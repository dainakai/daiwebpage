<!-- tips0001.md -->
<!-- Methods for Hyperparameter Search and Fine-tuning of Vision Models using Fastai, WandB, and timm -->
<!-- 2024-04-09 -->
When training image recognition models such as CNNs and Vision Transformers, there are several hyperparameters to explore. Articles like [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") and the [ConvNext paper](arXiv:2201.03545 "ConvNext paper") are very informative for hyperparameter tuning and other processes necessary to maximize performance. In this article, based on the above, I will summarize how to select models, tune parameters, and fine-tune for solving image recognition tasks using Fastai, WandB (Weights and Biases), and timm (Python Image Models).

## 1. Fine-tuning and its methods
Here's a brief explanation of fine-tuning. For more details, refer to [Deep Learning (Yoshua Bengio, et al.)](https://amzn.to/49FbFuT) and [Transfer Learning (Kota Matsui, Wataru Kumagai)](https://amzn.to/4d2gb9A).

Fine-tuning is a technique for applying a model pre-trained on a large dataset to a new (or custom) task. Let's call the pre-trained dataset the source domain and the new task's dataset the target domain. Because vision models acquire the ability to extract features from images through large-scale learning in the source domain, updating the model's parameters further using the target domain dataset can sometimes yield high performance.

The general steps are as follows:

1. Load a model pre-trained on the source domain dataset: In most cases, pre-trained models are loaded using libraries like [timm (PyTorch Image Models)](https://github.com/huggingface/pytorch-image-models).
2. Freeze part of the model: Freeze some layers of the model trained on the source domain dataset, such as the feature extraction Conv layers other than the head part (Dense layers for classification). Freezing means preventing the parameters of those layers from being updated.
3. Train on the target domain dataset: Update the model's parameters using the target domain dataset. At this point, update the parameters other than the frozen layers.
4. Unfreeze the model: At an advanced stage of training, unfreeze the frozen layers to allow their parameters to be updated. The model is frozen to prevent the parameters of the feature extraction layers from changing significantly due to the influence of the initial parameters of the added head layers.
5. Train the entire model: Finally, train the entire model on the target domain dataset.

There are variations in which layers to freeze and which layers to unfreeze after freezing. In some cases, the Conv layers may be frozen and trained until the end without unfreezing. This article assumes the method of freezing everything except the head for training, then unfreezing and training.

## 2. Fine-tuning using Fastai, WandB, and timm

The specific methods of fine-tuning, such as which layers to freeze and for how long, which layers to unfreeze, and how to set the gradient descent method, learning rate, and learning scheduling methods, are very important and difficult problems. Many model architectures are proposed, but it is often difficult to achieve sufficient performance with a uniform training method for them. Instead, it is necessary to focus on implementing the training methods (learning scheduling, selection of gradient descent methods, etc.) explained in the papers and tune the parameters. However, what to do can often be found heuristically, and trial and error is required, making it a challenging problem, especially for beginners like myself. Among them, the implementation in [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") is very informative as one of the best practices for training vision models. I highly recommend reading the article and tracing the training based on the published implementation. In this article, based on the results of tracing, I will summarize the training methods tailored to my task domain and their implementation.

### 2.1. timm (PyTorch Image Models)
timm is a library of image recognition models that can be used with PyTorch. It allows easy use of high-performance models such as ResNet, EfficientNet, ViT, and ConvNext. To see what kinds of high-performance models are available, take a look at [ImageNet Benchmark (Image Classification) | Papers With Code](https://paperswithcode.com/sota/image-classification-on-imagenet). timm also provides pre-trained models, making it easy to perform fine-tuning using them. Looking at the [GitHub repository](https://github.com/huggingface/pytorch-image-models), you can see the model architectures clearly written in the code, which is helpful for understanding the models. There are many models available from timm with similar names, even for a single model, but especially when using them for research, it is necessary to check the code to see what variations they are. Many models have versions that differ from the paper implementations.

The models available in timm are wrapped by fastai. So I will explain the detailed implementations in the next section.

### 2.2. Fine-tuning with Fastai
Fastai is a high-level machine learning framework that wraps the functionality of PyTorch and others for easy use. I think knowledge of PyTorch is still useful for detailed implementations (custom transforms, etc.). A great thing about Fastai is that the implementations and executions of learning rate scheduling and data augmentation are very simple, and they are properly in line with the trends of papers over time, so training can be done nicely even with default settings. The code shown below is mostly based on the [implementation shown in The best vision models for fine-tuning article](https://github.com/tcapelle/fastai_timm/blob/main/fine_tune.py), and the differences are the data loading method `get_dataset()` function, the additional transform `AddGaussianNoise` class, and the monitored evaluation metrics `accuracy, Recall(), Precision(), RocAucBinary()`. The optimal values obtained from hyperparameter tuning are set in `config_defaults`.

Here's an example of code for fine-tuning with Fastai:
::gist{#7f447cbd72ca56816350af7c3a6e200e}

### 2.3. Hyperparameter tuning and training tracking with WandB (Weights and Biases)
WandB is a service that allows you to track the progress and metrics of training in the cloud, and in addition to comparing different models, you can also perform hyperparameter tuning by specifying the range and search method of hyperparameters. If you pass a WandB callback to `vision_learner`, it automatically records the information for you, which is very convenient. Write a `settings.yaml` like the following to declare the search range and method. In this case, Bayesian optimization is used to sweep the `batch_size`, `learning_rate`, and `model_name` parameters to minimize the validation loss.

::gist{#1a3fdd68f3fa03cab63d92912acf907c}

The performance comparison of the trained models is visualized below.

https://api.wandb.ai/links/dai-personal/b9g3fq8r

## 3. Summary
I have summarized how to perform fine-tuning of vision models using Fastai, WandB, and timm. As I am not part of the machine learning community and am studying alone, I would greatly appreciate any corrections or suggestions for improvement. Also, I hope this article will be helpful to others in their learning.

There is one point that I am unsure about and concerned about. [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") declares the use of the AdamW optimizer as the gradient descent method, and [the implementation shown in The best vision models for fine-tuning article](https://github.com/tcapelle/fastai_timm/blob/main/fine_tune.py) does not have any specific optimizer settings and seems to use the default one, but according to the [vision_learner documentation](https://docs.fast.ai/vision.learner.html#vision_learner), the default seems to be Adam. Hmm... I noticed this while writing this article, but I think AdamW should be properly specified in the implementation.

Postscript: November 7, 2024
In Fastai, specifying the Adam optimizer defaults to using AdamW, so this concern has been resolved.
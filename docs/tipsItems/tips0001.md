<!-- tips0001.md -->
<!-- Fastai, WandB, timmによるビジョンモデルのパラメータ探索とファインチューニングの方法 -->
<!-- 2024-04-09 -->
CNNやVision Transformerなどの画像認識モデル（ビジョンモデル）の学習では、探索すべきハイパーパラメータがいくつかあります。こういったハイパラチューニングや、その他の性能を最大まで引き出すために必要なプロセスについては、例えば [The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") や [ConvNext論文](https://arxiv.org/abs/2201.03545 "ConvNext論文") が非常に参考になります。この記事では、上記を踏まえて、Fastai、WandB (Weights and Biases)、timm (Python Image Models) を活用して画像認識タスク解決のためのモデル選定・パラメータチューニング・ファインチューニングの方法についてまとめます。

## 1. ファインチューニングとその方法
ファインチューニングについて簡単に説明します。詳細は [深層学習（岡谷貴之）](https://amzn.to/49FbFuT) や [転移学習（松井孝太、熊谷 亘）](https://amzn.to/4d2gb9A) が参考なります。

ファインチューニングは、大規模なデータセットで事前学習したモデルを新しい（あるいは、独自の）タスクに適用するための手法です。事前学習したデータセットをソースドメイン、新しいタスクのデータセットをターゲットドメインとここで呼ぶことにします。ソースドメインの大規模な学習によってビジョンモデルは画像の特徴抽出能力を獲得するため、ターゲットドメインのデータセットを用いてさらにモデルのパラメータを更新することで高い性能を発揮する場合があります。

おおよそ以下の手順で行います。

1. ソースドメインのデータセットで事前学習したモデルを読み込む：多くの場合は [timm (PyTorch Image Models)](https://github.com/huggingface/pytorch-image-models) などのライブラリを使って、事前学習済みのモデルを読み込みます。
2. モデルの一部を凍結する：ソースドメインのデータセットで学習したモデルの一部、例えばhead部分（識別用のDense層）以外の特徴抽出用Conv層などを凍結します。凍結とは、その層のパラメータを更新しないようにすることです。
3. ターゲットドメインのデータセットで学習する：ターゲットドメインのデータセットを用いて、モデルのパラメータを更新します。このとき、凍結した層以外のパラメータを更新します。
4. モデルを解凍する：学習が進んできた段階で、凍結した層を解凍してパラメータを更新するようにします。モデルの凍結は、追加したhead層の初期パラメータの影響で特徴抽出層のパラメータが大きく変化してしまうことを防ぐために行います。
5. モデルの全体を学習する：最終的には、モデル全体をターゲットドメインのデータセットで学習します。

どの層を凍結するか、凍結したあとどの層を解凍するかはバリエーションがあります。Conv層を凍結したら解凍せずそのまま最後まで学習する場合もあります。この記事では、head以外を凍結して学習、その後解凍して学習する方法を前提として説明します。

## 2. Fastai、WandB、timmを使ったファインチューニング

ファインチューニングの具体的な方法、つまり、どの層をいつまで凍結するか、どの層を解凍するか、勾配降下法・学習率・学習スケジューリング手法をどのように設定するか、などは非常に重要かつ難しい問題です。いろいろなモデルアーキテクチャが提案されますが、それらに対して画一的な学習方法で十分な性能を引き出すことは難しい場合が多く、論文で説明されている学習手法（学習スケジューリング、勾配降下法の選択など）の実装を中心にパラメータチューニングを行う必要があります。とはいえ、何をしたら良いのかは発見的に見つかる場合も多く、試行錯誤が必要なため特に私も含む初学者にとっては難しい問題です。その中で、[The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") の実装はビジョンモデルの学習における一つのベストプラクティスとして非常に参考になります。ぜひ記事に目を通し、公開されている実装をもとに学習をトレースしてみることをお勧めします。この記事では、トレースした結果をもとに、私のタスクドメインに合わせた学習方法とその実装についてまとめます。

### 2.1. timm (PyTorch Image Models)
timmは、PyTorchで使える画像認識モデルのライブラリです。ResNet、EfficientNet、ViT、ConvNextなど性能の高いモデルを簡単に利用できます。どんな性能の高いモデルがあるのかについては、たとえば [ImageNet Benchmark (Image Classification) | Papers With Code](https://paperswithcode.com/sota/image-classification-on-imagenet) を見てみてください。timmは、事前学習済みのモデルも提供しており、これを使うことでファインチューニングを簡単に行うことができます。[Githubリポジトリ](https://github.com/huggingface/pytorch-image-models) を見るとモデルの構成もわかりやすくコードに書かれているので、モデルの理解にも役立ちます。timmから使えるモデルは一つのモデルでも似たような名前のものがたくさんありますが、特に研究などで使う場合はそれぞれがどのようなバリエーションなのかコードで確認する必要があります。論文実装とは異なるバージョンがあるモデルも多いです。

timmで使えるモデルはfastaiでラップされています。なので細かな実装は次節で説明します。

### 2.2. Fastaiによるファインチューニング
Fastaiは、PyTorchなどの機能を簡単に使えるようにラップした高レベルな機械学習フレームワークです。細かな実装（自前のトランスフォームなど）をするにはやはりPyTorchの知識があるよいかと思います。Fastaiのよいところは、学習率スケジューリングやデータ拡張などの実装と実行が非常に簡単で、またそれらがきちんと論文の時代の流れに沿っているのでデフォルトの設定でもいい感じに学習ができることです。下に示すコードは、[The best vision models for fine-tuning 記事中で示されている実装](https://github.com/tcapelle/fastai_timm/blob/main/fine_tune.py) の大部分を参考にしており、これと異なる点はデータのロード方法 ```get_dataset()```関数、追加のトランスフォーム ```AddGaussianNoise```クラス、監視する評価メトリクス ```accuracy, Recall(), Precision(), RocAucBinary()```くらいです。ハイパーパラメータチューニングで得た最適な値を ```config_defaults``` に設定しています。

Fastaiでファインチューニングするコードの例を以下に示します。
::gist{#7f447cbd72ca56816350af7c3a6e200e}

### 2.3. WandB (Weights and Biases)によるハイパーパラメータチューニングと学習のトラッキング
WandBは学習の進行状況やメトリクスをクラウドでトラッキングできるサービスで、異なるモデルの比較はもちろん、ハイパーパラメータの範囲と探索手法を指定してハイパーパラメータチューニングを行うこともできます。```vision_learner``` にWandBのコールバックを渡せば自動で情報を記録してくれるので非常に楽です。次のような ```settings.yaml``` を書いて探索範囲と手法を宣言します。この場合は，ベイズ最適化でValidation lossを最小化するために ```batch_size```, ```learning_rate```, ```model_name``` のパラメータを掃引 (sweep) します。

::gist{#1a3fdd68f3fa03cab63d92912acf907c}

学習したモデルの性能比較を以下に可視化しています。

https://api.wandb.ai/links/dai-personal/b9g3fq8r

## 3. まとめ
Fastai、WandB、timmを使ってビジョンモデルのファインチューニングを行う方法についてまとめました。私自身は機械学習のコミュニティに属してはおらず一人で勉強しているため、間違っている点やこうしたほうがよいなどのアドバイスがあればぜひ連絡をいただきたいです。また、この記事が他の方の学習に少しでも役立てば幸いです。

一点だけ私も良くわからず気になる点があります。[The best vision models for fine-tuning](https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning/notebook "The best vision models for fine-tuning") では勾配降下法としてAdamWオプティマイザを使うと宣言していて、[The best vision models for fine-tuning 記事中で示されている実装](https://github.com/tcapelle/fastai_timm/blob/main/fine_tune.py) では特にオプティマイザの設定がなくデフォルトのものが使われているようですが、[vision_learnerのドキュメント](https://docs.fast.ai/vision.learner.html#vision_learner) ではデフォルトはAdamみたいです。アララ…。この記事を書いていて気づきましたが、実装の際はきちんとAdamWを指定すべきかと思います。

追記: 2024/11/7
fastaiではAdamオプティマイザを指定するとデフォルトでAdamWが使われるのでこの懸念は解消されました。